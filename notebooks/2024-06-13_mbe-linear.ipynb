{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtomy-lorant\u001b[0m (\u001b[33mlorant\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import esm\n",
    "\n",
    "# log into to wandb to log results\n",
    "import wandb\n",
    "\n",
    "WANDB_NOTEBOOK_NAME = '2024-06-13_mbe-linear.ipynb'\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "datadir = '../out/corrected/counts'\n",
    "procdir = '../out/modelling/processed'\n",
    "BATCH_SIZE=64\n",
    "\n",
    "os.makedirs(procdir, exist_ok=True)\n",
    "np.random.seed(12345)\n",
    "rerun_encoding = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import\n",
    "Load the r0 and r1 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../out/corrected/counts/2024-06-05_r0_np-cc_aa-seq-counts.tsv.gz',\n",
       " '../out/corrected/counts/2024-06-05_r1_np-cc_aa-seq-counts.tsv.gz',\n",
       " '../out/corrected/counts/2024-06-05_r0_np-cc_gel-extract_aa-seq-counts.tsv.gz',\n",
       " '../out/corrected/counts/2024-06-05_r0_np-cc_repeat_aa-seq-counts.tsv.gz',\n",
       " '../out/corrected/counts/2024-06-05_r1_np-cc_gel-extract_aa-seq-counts.tsv.gz']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get files to be imported\n",
    "files = glob.glob(os.path.join(datadir, '2024-06-05_r[0-1]_np-cc*aa-seq-counts.tsv.gz'))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>sequence</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r0</td>\n",
       "      <td>MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r0</td>\n",
       "      <td>MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r0</td>\n",
       "      <td>MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r0</td>\n",
       "      <td>MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r0</td>\n",
       "      <td>MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNRRGLV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243361</th>\n",
       "      <td>r1</td>\n",
       "      <td>MAADGYLPDWLEDTLSEGISEWWALKPGVPQPKANQQHQDNRRGLV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243362</th>\n",
       "      <td>r1</td>\n",
       "      <td>MAADGYLPDWLEDTLSEGISEWWALKPGVPQPKANQQHQDNRRGLV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243363</th>\n",
       "      <td>r1</td>\n",
       "      <td>MAADGYLPDWLEDTLSEGISEWWKLKPGPPPPKPAERHKDDGRGLV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243364</th>\n",
       "      <td>r1</td>\n",
       "      <td>MAADGYLPDWLEDTLSEGISEWWKLKPGPPPPKPAERHQDNSRGLV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243365</th>\n",
       "      <td>r1</td>\n",
       "      <td>MAADGYLPDWLEDTLSEGISQWWKLKPGPPPPKPAERHKDDSRGLV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1243366 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        round                                           sequence  count\n",
       "0          r0  MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...      1\n",
       "1          r0  MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...      1\n",
       "2          r0  MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...      1\n",
       "3          r0  MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...      1\n",
       "4          r0  MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNRRGLV...      1\n",
       "...       ...                                                ...    ...\n",
       "1243361    r1  MAADGYLPDWLEDTLSEGISEWWALKPGVPQPKANQQHQDNRRGLV...      1\n",
       "1243362    r1  MAADGYLPDWLEDTLSEGISEWWALKPGVPQPKANQQHQDNRRGLV...      1\n",
       "1243363    r1  MAADGYLPDWLEDTLSEGISEWWKLKPGPPPPKPAERHKDDGRGLV...      1\n",
       "1243364    r1  MAADGYLPDWLEDTLSEGISEWWKLKPGPPPPKPAERHQDNSRGLV...      1\n",
       "1243365    r1  MAADGYLPDWLEDTLSEGISQWWKLKPGPPPPKPAERHKDDSRGLV...      1\n",
       "\n",
       "[1243366 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read tsv files\n",
    "df = pd.concat([pd.read_csv(f, sep='\\t').assign(round = os.path.basename(f)[11:13]) for f in files], axis=0)\n",
    "\n",
    "# sum counts within each round\n",
    "df = df.groupby(['round', 'sequence']).sum().reset_index()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of unique sequences and total count in each round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique sequences in each round:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "round\n",
       "r0    801140\n",
       "r1    442226\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of unique sequences in each round:\")\n",
    "df.groupby('round').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count for each round:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>round</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r0</th>\n",
       "      <td>941365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1</th>\n",
       "      <td>633141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "round        \n",
       "r0     941365\n",
       "r1     633141"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Total count for each round:\")\n",
    "total = (df\n",
    "         .drop('sequence', axis=1)\n",
    "         .groupby('round')\n",
    "         .sum()\n",
    "         )\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a higher total count for r0 compared to r1.  We will need to take this into account during modelling by weighting the loss function.\n",
    "\n",
    "Plotting the CDF of counts for the two libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='count', ylabel='Proportion'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.ecdfplot(data=df, x='count', hue='round')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.ecdfplot(data=df, x='count', hue='round', )\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test/eval sets\n",
    "We will need to remove a dataset for evaluation and testing.  Most sequences have low counts, so we try to get some with high counts in each set. \n",
    "\n",
    "For this, we caculate a set of weights according to the model-based enrichment paper, and then include some observations with high and low weights.  The weights are caculated as follows:\n",
    "\n",
    "$$w_i = \\frac{1}{(2\\sigma_i^2)}$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\\sigma_i^2 = \\frac{1}{n_i^{r_1}}(1-\\frac{n_i^{r_1}}{\\sum_i n^{r_1}_i}) + \\frac{1}{n_i^{r_0}}(1-\\frac{n_i^{r_0}}{\\sum_i n^{r_0}_i})$$\n",
    "\n",
    "Where $n_i^{r_0}$ is the count for the $i^{th}$ sequence in the round 0 library, and $n_i^{r_1}$ is the count for the $i^{th}$ sequence in the round 1 library.  This value is high if the counts in both libraries are high, and low if the counts in both libraries are low.  First calculating this for each sequence, and plotting the distribution.\n",
    "\n",
    "We also need to add a pseudo-count of 1 to all observations for this quantitity to be defined.\n",
    "\n",
    "I also calculate the log enrichment (`le`), which we'll compare against the density ratio for the validation and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>round</th>\n",
       "      <th>sequence</th>\n",
       "      <th>r0</th>\n",
       "      <th>r1</th>\n",
       "      <th>le</th>\n",
       "      <th>sig</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.222293</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217095</th>\n",
       "      <td>MAADGYLPDWLEDTLSEGISEWWKLKPGPPPPKPAERHKDDGRGLV...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.222293</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217096</th>\n",
       "      <td>MAADGYLPDWLEDTLSEGISEWWKLKPGPPPPKPAERHKDDSRGLV...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217097</th>\n",
       "      <td>MAADGYLPDWLEDTLSEGISEWWKLKPGPPPPKPAERHQDNSRGLV...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.222293</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217098</th>\n",
       "      <td>MAADGYLPDWLEDTLSEGISQWWKLKPGPPPPKPAERHKDDSRGLV...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.222293</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217099</th>\n",
       "      <td>MAADGYLPDWLEDTLSEGISQWWKLKPGPPPPKPAERHKDDSRGLV...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1217100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "round                                             sequence   r0   r1  \\\n",
       "0        MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...  2.0  1.0   \n",
       "1        MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...  2.0  1.0   \n",
       "2        MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...  1.0  2.0   \n",
       "3        MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...  2.0  1.0   \n",
       "4        MAADGYLPDWLEDNLCEGIREWWALKPGAPKPKANQQHQDNARGLV...  2.0  1.0   \n",
       "...                                                    ...  ...  ...   \n",
       "1217095  MAADGYLPDWLEDTLSEGISEWWKLKPGPPPPKPAERHKDDGRGLV...  1.0  2.0   \n",
       "1217096  MAADGYLPDWLEDTLSEGISEWWKLKPGPPPPKPAERHKDDSRGLV...  2.0  1.0   \n",
       "1217097  MAADGYLPDWLEDTLSEGISEWWKLKPGPPPPKPAERHQDNSRGLV...  1.0  2.0   \n",
       "1217098  MAADGYLPDWLEDTLSEGISQWWKLKPGPPPPKPAERHKDDSRGLV...  1.0  2.0   \n",
       "1217099  MAADGYLPDWLEDTLSEGISQWWKLKPGPPPPKPAERHKDDSRGLV...  2.0  1.0   \n",
       "\n",
       "round          le       sig    weight  \n",
       "0       -0.777707  1.499999  0.333334  \n",
       "1       -0.777707  1.499999  0.333334  \n",
       "2        1.222293  1.499999  0.333334  \n",
       "3       -0.777707  1.499999  0.333334  \n",
       "4       -0.777707  1.499999  0.333334  \n",
       "...           ...       ...       ...  \n",
       "1217095  1.222293  1.499999  0.333334  \n",
       "1217096 -0.777707  1.499999  0.333334  \n",
       "1217097  1.222293  1.499999  0.333334  \n",
       "1217098  1.222293  1.499999  0.333334  \n",
       "1217099 -0.777707  1.499999  0.333334  \n",
       "\n",
       "[1217100 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseduo = 1\n",
    "df_unique = (df\n",
    "             # add pseudocunt\n",
    "             .assign(count = lambda x: x['count'] + pseduo)\n",
    "             # r0 and 1 counts in separate columns\n",
    "             .pivot(index='sequence', columns='round', values='count')\n",
    "             .fillna(pseduo)\n",
    "             .reset_index()\n",
    "             # calculate log enrichment and weights as per MBE paper\n",
    "             .assign(\n",
    "                le = lambda x: np.log2((x['r1']/x['r1'].sum())/(x['r0']/x['r0'].sum())),\n",
    "                sig = lambda x: 1/x['r1']*(1-x['r1']/(x['r1'].sum())) + 1/x['r0']*(1-x['r0']/(x['r0'].sum())),\n",
    "                weight = lambda x: 1/(2*x['sig']),\n",
    "                     )\n",
    "             )\n",
    "df_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='sig', ylabel='Proportion'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.ecdfplot(data = df_unique, x = \"sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='weight', ylabel='Proportion'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.ecdfplot(data=df_unique, x='weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing quantiles for the numeric columns will give us an idea of where might be a good threshold for high and low counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>round</th>\n",
       "      <th>r0</th>\n",
       "      <th>r1</th>\n",
       "      <th>le</th>\n",
       "      <th>sig</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.743492</td>\n",
       "      <td>0.007153</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.362670</td>\n",
       "      <td>1.333332</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.333332</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.40</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.55</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.65</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.222293</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.222293</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.222293</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.222293</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.222293</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.222293</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.807255</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "round   r0   r1        le       sig    weight\n",
       "0.00   1.0  1.0 -6.743492  0.007153  0.333334\n",
       "0.05   1.0  1.0 -1.362670  1.333332  0.333334\n",
       "0.10   1.0  1.0 -0.777707  1.333332  0.333334\n",
       "0.15   1.0  1.0 -0.777707  1.499999  0.333334\n",
       "0.20   1.0  1.0 -0.777707  1.499999  0.333334\n",
       "0.25   1.0  1.0 -0.777707  1.499999  0.333334\n",
       "0.30   1.0  1.0 -0.777707  1.499999  0.333334\n",
       "0.35   2.0  1.0 -0.777707  1.499999  0.333334\n",
       "0.40   2.0  1.0 -0.777707  1.499999  0.333334\n",
       "0.45   2.0  1.0 -0.777707  1.499999  0.333334\n",
       "0.50   2.0  1.0 -0.777707  1.499999  0.333334\n",
       "0.55   2.0  1.0 -0.777707  1.499999  0.333334\n",
       "0.60   2.0  1.0 -0.777707  1.499999  0.333334\n",
       "0.65   2.0  2.0  0.222293  1.499999  0.333334\n",
       "0.70   2.0  2.0  1.222293  1.499999  0.333334\n",
       "0.75   2.0  2.0  1.222293  1.499999  0.333334\n",
       "0.80   2.0  2.0  1.222293  1.499999  0.333334\n",
       "0.85   2.0  2.0  1.222293  1.499999  0.333334\n",
       "0.90   2.0  2.0  1.222293  1.499999  0.375000\n",
       "0.95   3.0  3.0  1.807255  1.499999  0.375000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.quantile(np.arange(0, 1, 0.05), numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These weights have a very skewed distribution (as do the counts) - this might be an issue for modelling, since only a few high-count sequences will dominate the results. \n",
    "\n",
    "It would be good to try to keep the test and eval sets roughly balanced, with sequences with high and low weights. For this, we will take equal numbers of sequences from the top 10% and the bottom 90%.  We will need to keep these sets small, since otherwise we'll be removing most of the training data. I'll define 'high-confidence' sequences those weights equal to or higher than 1, and 'low-confidence' sequences those with weights lower than 1.  I'll take 50 sequences from each set for each of the eval and test sets.\n",
    "\n",
    "First, checking how many 'high-confidence' and 'low-confidence' sequences we have with this threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set\n",
       "low     1212856\n",
       "high       4244\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 1\n",
    "df_unique = df_unique.assign(set = lambda x: ['high' if w >= thresh else 'low' for w in x['weight']])\n",
    "df_unique.value_counts('set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(set\n",
       " high    50\n",
       " low     50\n",
       " Name: count, dtype: int64,\n",
       " set\n",
       " high    50\n",
       " low     50\n",
       " Name: count, dtype: int64,\n",
       " set\n",
       " low     1212756\n",
       " high       4144\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_eval = df_unique.sample(frac=1).groupby('set').head(100)\n",
    "df_test = df_test_eval.groupby('set').head(50)\n",
    "\n",
    "# remove test set from evaluation set\n",
    "df_eval = df_test_eval[~df_test_eval['sequence'].isin(df_test['sequence'])]\n",
    "df_train = df_unique[~df_unique['sequence'].isin(df_test_eval['sequence'])]\n",
    "\n",
    "# check we have 50 sequences in each set, and remainder in training set\n",
    "df_eval.value_counts('set'), df_test.value_counts('set'), df_train.value_counts('set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding sequences\n",
    "\n",
    "In this case I one-hot encode the data.  It's more effecient to encode the unique sequences rather than the full training set for model-based enrichment, so I'll do this now and save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aas = [i for i in 'ACDEFGHIKLMNPQRSTVWY*']\n",
    "def one_hot(seq, max_l):\n",
    "    \"\"\"\n",
    "    One hot encode a sequence of amino acids\n",
    "    \"\"\"\n",
    "    out = np.zeros((max_l, len(aas)))\n",
    "    for i in range(max_l):\n",
    "        if i < len(seq):\n",
    "            out[i, aas.index(seq[i])] = 1\n",
    "    return out.flatten()\n",
    "\n",
    "one_hot('ACD', 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodign the sequences with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aas = [i for i in 'ACDEFGHIKLMNPQRSTVWY*']\n",
    "print(type(aas))\n",
    "def label_encoding(seq, max_l):\n",
    "    \"\"\"\n",
    "    Encode a sequence of amino acids with integer valus for each type fo amino acid\n",
    "    \"\"\"\n",
    "    out = np.zeros(max_l)\n",
    "    label_encoder = LabelEncoder().fit(aas)\n",
    "    encoded = label_encoder.transform(list(seq))\n",
    "    out[:len(seq)] = encoded\n",
    "    return out\n",
    "\n",
    "label_encoding('ACD', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "740"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len = max(len(seq) for seq in df_train['sequence'])\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737\n",
      "738\n",
      "737\n",
      "735\n",
      "737\n"
     ]
    }
   ],
   "source": [
    "def esm_embedding(seqs, max_len):\n",
    "    # print(seqs)\n",
    "    \n",
    "    # data = [(round_val[0], seqs.loc[round_val[0], 'sequence'][:len(seqs.loc[round_val, 'sequence']) - 1]) for round_val in seqs.index.tolist()]\n",
    "    data = [(str(round_val), sequence + \"<pad>\" * (max_len - len(sequence))) for round_val, sequence in seqs]\n",
    "    # print(\"DATAA: \", data[0][1])\n",
    "    model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "\n",
    "    # print(\"alphabet: \", alphabet.all_toks)\n",
    "\n",
    "    batch_converter = alphabet.get_batch_converter(max_len)\n",
    "    model.eval()\n",
    "\n",
    "    batch_labels, batch_seq, batch_tokens = batch_converter(data)\n",
    "    \n",
    "    # batch_lens is just an array with the length of all of the sequences\n",
    "    # and alphabet.padding_idx is jus thte index of the token '<pad>' in the alpahabet token list\n",
    "    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "    # print(\"batch lengtsh: \", batch_lens)\n",
    "    # Extract per-residue representations (on CPU)\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "    token_representations = results[\"representations\"][33]\n",
    "    # print(\"token represntation shpae: \", token_representations.shape)\n",
    "    # print(\"token represetations: \", token_representations)\n",
    "    # print(\"token_rep [0] length: \", token_representations[0].shape)\n",
    "    # Generate per-sequence representations via averaging\n",
    "    # # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
    "    sequence_representations = []\n",
    "    for i, tokens_len in enumerate(batch_lens):\n",
    "        sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(1))\n",
    "    # print(sequence_representations[1].shape)\n",
    "    return batch_labels, sequence_representations\n",
    "\n",
    "\n",
    "round_sequence_list = [(round_val, df_train.head().loc[round_val, 'sequence'][:len(df_train.head().loc[round_val, 'sequence']) - 1]) for round_val in df_train.head().index.tolist()]\n",
    "# round_sequence_list[0][1]\n",
    "\n",
    "embeddings = esm_embedding(round_sequence_list, max_seq_len + 10)\n",
    "for x in embeddings[1]:\n",
    "    print(len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'esm_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m     out\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoded\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_encoded\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m---> 23\u001b[0m df_train_test \u001b[38;5;241m=\u001b[39m \u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m750\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# print(df_train_test['encoded'][0])\u001b[39;00m\n\u001b[1;32m     26\u001b[0m df_train_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoded\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m, in \u001b[0;36mencode\u001b[0;34m(df, max_len)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(df, max_len):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Extract the index (or this case the round number) and the amino acid sequence of each entry in the data frame\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# index_and_sequence = [(round_val, df.loc[round_val, 'sequence'][:len(df.loc[round_val, 'sequence']) - 1]) for round_val in df.index.tolist()]\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     index_and_sequence \u001b[38;5;241m=\u001b[39m [(round_val, df\u001b[38;5;241m.\u001b[39mloc[round_val, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<eos>\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m round_val \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mtolist()]\n\u001b[0;32m----> 5\u001b[0m     indexes, encoded_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mesm_embedding\u001b[49m(index_and_sequence, max_len)\n\u001b[1;32m      7\u001b[0m     numpy_arrays \u001b[38;5;241m=\u001b[39m [tensor\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m encoded_tensor]\n\u001b[1;32m      9\u001b[0m     df_encoded \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mround\u001b[39m\u001b[38;5;124m'\u001b[39m: indexes,\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoded\u001b[39m\u001b[38;5;124m'\u001b[39m: numpy_arrays\n\u001b[1;32m     12\u001b[0m     })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'esm_embedding' is not defined"
     ]
    }
   ],
   "source": [
    "def encode(df, max_len):\n",
    "    # Extract the index (or this case the round number) and the amino acid sequence of each entry in the data frame\n",
    "    # index_and_sequence = [(round_val, df.loc[round_val, 'sequence'][:len(df.loc[round_val, 'sequence']) - 1]) for round_val in df.index.tolist()]\n",
    "    index_and_sequence = [(round_val, df.loc[round_val, 'sequence'].replace('*', '<eos>')) for round_val in df.index.tolist()]\n",
    "    indexes, encoded_tensor = esm_embedding(index_and_sequence, max_len)\n",
    "\n",
    "    numpy_arrays = [tensor.numpy() for tensor in encoded_tensor]\n",
    "    \n",
    "    df_encoded = pd.DataFrame({\n",
    "        'round': indexes,\n",
    "        'encoded': numpy_arrays\n",
    "    })\n",
    "\n",
    "    df_encoded.set_index('round', inplace=True)\n",
    "    df_encoded.index = df_encoded.index.astype('int64')\n",
    "\n",
    "    out = df\n",
    "    # out['encoded'] = df_encoded\n",
    "    out.loc[:,'encoded'] = df_encoded\n",
    "    \n",
    "    return out\n",
    "\n",
    "df_train_test = encode(df_train.head(), 750)\n",
    "\n",
    "# print(df_train_test['encoded'][0])\n",
    "df_train_test['encoded'][0].shape\n",
    "for x in df_train_test['encoded']:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train.iloc[11]['sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "736"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train.iloc[12]['sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode datasets\n",
    "def encode(df, max_seq_length):\n",
    "    df = (df\n",
    "          .assign(encoded = df['sequence'].apply(lambda x: label_encoding(x, max_seq_length)))\n",
    "          .drop('sequence', axis=1)\n",
    "          )\n",
    "    return df\n",
    "\n",
    "# def encode(df):\n",
    "#     index_and_sequence = [(round_val, df.loc[round_val, 'sequence'][:len(df.loc[round_val, 'sequence']) - 1]) for round_val in df.index.tolist()]\n",
    "#     indexes, encoded_tensor = esm_embedding(index_and_sequence)\n",
    "\n",
    "#     numpy_arrays = [tensor.numpy() for tensor in encoded_tensor]\n",
    "    \n",
    "#     out = pd.DataFrame({\n",
    "#         'index': indexes,\n",
    "#         'encoded': numpy_arrays\n",
    "#     })\n",
    "\n",
    "#     out.set_index('Index', inplace=True)\n",
    "\n",
    "#     return out.join(df, how='inner')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "max_seq_length = df_unique['sequence'].str.len().max() + 10\n",
    "# rerun_encoding = True\n",
    "\n",
    "# if not os.path.exists(os.path.join(procdir, 'train_ESM_embedding.pkl')) or rerun_encoding:\n",
    "if not os.path.exists(os.path.join(procdir, 'train_label_encoding.pkl')) or rerun_encoding:\n",
    "    print(\"recoding\")\n",
    "    # max_seq_length = df_unique['sequence'].str.len().max() + 10\n",
    "    df_train = encode(df_train, max_seq_length)\n",
    "    print('after df_train')\n",
    "    df_eval = encode(df_eval, max_seq_length)\n",
    "    print(\"after df_eval\")\n",
    "    df_test = encode(df_test, max_seq_length)\n",
    "    \n",
    "    # save data\n",
    "    df_train.to_pickle(os.path.join(procdir, 'train_label_encoding.pkl'))\n",
    "    df_eval.to_pickle(os.path.join(procdir, 'eval_label_encoding.pkl'))\n",
    "    df_test.to_pickle(os.path.join(procdir, 'test_label_encoding.pkl'))\n",
    "\n",
    "else:\n",
    "    \n",
    "    #df_train = pd.read_pickle(os.path.join(procdir, 'train.pkl')) # too large\n",
    "    df_eval = pd.read_pickle(os.path.join(procdir, 'eval_label_encoding.pkl'))\n",
    "    df_test = pd.read_pickle(os.path.join(procdir, 'test_label_encoding.pkl'))\n",
    "    # max_seq_length would not be defined if the dfs were already loaded inan external file\n",
    "    # max_seq_length = max(len(x) for x in df_eval['encoded'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['r0', 'r1', 'le', 'sig', 'weight', 'set', 'encoded'], dtype='object', name='round')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = encode(df_train.head(), max_seq_length)\n",
    "tt.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-based enrichment dataset\n",
    "\n",
    "For model based enrichment, we create a dataset where we sample sequences the number of times they were seen in each selection round.  For each sample, the sequence is labelled according to which round it appeared in: -1 for r0 and +1 for r1.  For example, if we have a sequence that was seen once in r0 and twice in r1, it would appear in the final dataset once with a label of -1 and twice with a label of +1.\n",
    "\n",
    "Note that the paper describes using class labels of -1 and +1, and they say they use 'standard logistic loss'.  However, the loss function they describe looks slightly different to the [`BCELoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html) in pytorch, probably mostly because the pytorch version expects class labels of 0 and 1 (which are more standard).  Since it's easier (and probably much faster) to the use BCELoss function from pytorch, I'll also use class labels of 0 and 1.\n",
    "\n",
    "The evaluation set would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded</th>\n",
       "      <th>round</th>\n",
       "      <th>count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....</td>\n",
       "      <td>r0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....</td>\n",
       "      <td>r0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....</td>\n",
       "      <td>r0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....</td>\n",
       "      <td>r0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....</td>\n",
       "      <td>r0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>[10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....</td>\n",
       "      <td>r1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>[10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....</td>\n",
       "      <td>r1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>[10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....</td>\n",
       "      <td>r1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>[10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....</td>\n",
       "      <td>r1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>[10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....</td>\n",
       "      <td>r1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               encoded round  count  label\n",
       "0    [10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....    r0    2.0      0\n",
       "0    [10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....    r0    2.0      0\n",
       "1    [10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....    r0    1.0      0\n",
       "2    [10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....    r0    1.0      0\n",
       "3    [10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....    r0    1.0      0\n",
       "..                                                 ...   ...    ...    ...\n",
       "199  [10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....    r1    7.0      1\n",
       "199  [10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....    r1    7.0      1\n",
       "199  [10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....    r1    7.0      1\n",
       "199  [10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....    r1    7.0      1\n",
       "199  [10.0, 0.0, 0.0, 2.0, 5.0, 19.0, 9.0, 12.0, 2....    r1    7.0      1\n",
       "\n",
       "[1058 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add labels to data based on if the sequence base observed in the r0 and r1 libraries\n",
    "df_example = (df_eval\n",
    "                .loc[:, ['encoded', 'r0', 'r1']]\n",
    "                .melt(id_vars = 'encoded', value_vars = ['r0', 'r1'], var_name = 'round', value_name = 'count')\n",
    "                .assign(label = lambda x: (x['round'] == 'r1').astype(int))\n",
    "                )\n",
    "\n",
    "# sample sequences according to their count\n",
    "df_example = df_example.reindex(df_example.index.repeat(df_example['count']))\n",
    "\n",
    "df_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving to paruqet file (not pickle files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>round</th>\n",
       "      <th>r0</th>\n",
       "      <th>r1</th>\n",
       "      <th>le</th>\n",
       "      <th>sig</th>\n",
       "      <th>weight</th>\n",
       "      <th>set</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>463203</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "      <td>low</td>\n",
       "      <td>[11.0, 1.0, 1.0, 3.0, 6.0, 20.0, 10.0, 13.0, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042262</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "      <td>low</td>\n",
       "      <td>[11.0, 1.0, 1.0, 3.0, 6.0, 20.0, 10.0, 13.0, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95225</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "      <td>low</td>\n",
       "      <td>[11.0, 1.0, 1.0, 3.0, 6.0, 20.0, 10.0, 13.0, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561907</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "      <td>low</td>\n",
       "      <td>[11.0, 1.0, 1.0, 3.0, 6.0, 20.0, 10.0, 13.0, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146424</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "      <td>low</td>\n",
       "      <td>[11.0, 1.0, 1.0, 3.0, 6.0, 20.0, 10.0, 13.0, 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "round     r0   r1        le       sig    weight  set  \\\n",
       "463203   2.0  1.0 -0.777707  1.499999  0.333334  low   \n",
       "1042262  2.0  1.0 -0.777707  1.499999  0.333334  low   \n",
       "95225    2.0  1.0 -0.777707  1.499999  0.333334  low   \n",
       "561907   2.0  1.0 -0.777707  1.499999  0.333334  low   \n",
       "146424   2.0  1.0 -0.777707  1.499999  0.333334  low   \n",
       "\n",
       "round                                              encoded  \n",
       "463203   [11.0, 1.0, 1.0, 3.0, 6.0, 20.0, 10.0, 13.0, 3...  \n",
       "1042262  [11.0, 1.0, 1.0, 3.0, 6.0, 20.0, 10.0, 13.0, 3...  \n",
       "95225    [11.0, 1.0, 1.0, 3.0, 6.0, 20.0, 10.0, 13.0, 3...  \n",
       "561907   [11.0, 1.0, 1.0, 3.0, 6.0, 20.0, 10.0, 13.0, 3...  \n",
       "146424   [11.0, 1.0, 1.0, 3.0, 6.0, 20.0, 10.0, 13.0, 3...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tt = encode(df_test.head(), 750)\n",
    "\n",
    "df_tt.to_parquet(os.path.join(procdir, 'testing.parquet'))\n",
    "\n",
    "read_tt = pd.read_parquet(os.path.join(procdir, 'testing.parquet'))\n",
    "\n",
    "read_tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing getting the data from a .pkl file with dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>round</th>\n",
       "      <th>r0</th>\n",
       "      <th>r1</th>\n",
       "      <th>le</th>\n",
       "      <th>sig</th>\n",
       "      <th>weight</th>\n",
       "      <th>set</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>463203</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.777707</td>\n",
       "      <td>1.499999</td>\n",
       "      <td>0.333334</td>\n",
       "      <td>low</td>\n",
       "      <td>[11.  1.  1.  3.  6. 20. 10. 13.  3. 19. 10.  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "round    r0   r1        le       sig    weight  set  \\\n",
       "463203  2.0  1.0 -0.777707  1.499999  0.333334  low   \n",
       "\n",
       "round                                             encoded  \n",
       "463203  [11.  1.  1.  3.  6. 20. 10. 13.  3. 19. 10.  ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# I have to get the data form the label encoding files because I haven't been able to create the ones for ESM :(\n",
    "\n",
    "ddf = dd.read_parquet(os.path.join(procdir, 'testing.parquet'))\n",
    "\n",
    "row_number = 463203\n",
    "specific_row = ddf.loc[row_number].compute()\n",
    "\n",
    "specific_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "\n",
    "Creating a dataset and dataloader class for these datasets.  I wrap some of the code from earlier in a lightning data module class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10.,  0.,  0.,  2.,  5., 19.,  9., 12.,  2., 18.,  9.,  3.,  2.,\n",
       "        16.,  9., 15.,  3.,  5.,  7., 14., 13., 18., 18.,  8.,  9.,  8.,\n",
       "        12.,  5., 12., 12., 12., 12.,  8., 12.,  0.,  3., 14.,  6.,  8.,\n",
       "         2.,  2., 15., 14.,  5.,  9., 17.,  9., 12.,  5., 19.,  8., 19.,\n",
       "         9.,  5., 12.,  4., 11.,  5.,  9.,  2.,  8.,  5.,  3., 12., 17.,\n",
       "        11.,  3.,  0.,  2.,  0.,  0.,  0.,  9.,  3.,  6.,  2.,  8.,  0.,\n",
       "        19.,  2., 14., 13.,  9.,  2., 15.,  5.,  2., 11., 12., 19.,  9.,\n",
       "         8., 19., 11.,  6.,  0.,  2.,  0.,  3.,  4., 13.,  3., 14.,  9.,\n",
       "         8.,  3.,  2., 16., 15.,  4.,  5.,  5., 11.,  9.,  5., 14.,  0.,\n",
       "        17.,  4., 13.,  0.,  8.,  8., 14., 17.,  9.,  3., 12.,  9.,  5.,\n",
       "         9., 17.,  3.,  3.,  0.,  0.,  8., 16.,  0., 12.,  5.,  8.,  8.,\n",
       "        14., 12., 17.,  2., 13., 15., 12., 13.,  3., 12.,  2., 15., 15.,\n",
       "        15.,  5., 17.,  5.,  8., 15.,  5.,  8., 13., 12.,  0., 14.,  8.,\n",
       "        14.,  9., 11.,  4.,  5., 13., 16.,  5.,  2., 15.,  3., 15., 17.,\n",
       "        12.,  2., 12., 13., 12.,  9.,  5.,  3., 12., 12.,  0.,  0., 12.,\n",
       "        16., 15.,  9.,  5., 15., 11., 16., 10.,  0., 15.,  5.,  5.,  5.,\n",
       "         0., 12., 10.,  0.,  2., 11., 11.,  3.,  5.,  0.,  2.,  5., 17.,\n",
       "         5., 15., 15., 15.,  5., 11., 18.,  6.,  1.,  2., 15., 13., 18.,\n",
       "         9.,  5.,  2., 14., 17.,  7., 16., 16., 15., 16., 14., 16., 18.,\n",
       "         0.,  9., 12., 16., 19., 11., 11.,  6.,  9., 19.,  8., 13.,  7.,\n",
       "        15., 11.,  5., 16., 15.,  5.,  5.,  0., 16., 11.,  2., 11., 16.,\n",
       "        19.,  4.,  5., 19., 15., 16., 12., 18.,  5., 19.,  4.,  2.,  4.,\n",
       "        11., 14.,  4.,  6.,  1.,  6.,  4., 15., 12., 14.,  2., 18., 13.,\n",
       "        14.,  9.,  7., 11., 11., 11., 18.,  5.,  4., 14., 12.,  8., 14.,\n",
       "         9., 11.,  4.,  8.,  9.,  4., 11.,  7., 13., 17.,  8.,  3., 17.,\n",
       "        16.,  2., 11., 11.,  5., 17.,  8., 16.,  7.,  0., 11., 11.,  9.,\n",
       "        16., 15., 16., 17., 13., 17.,  4., 16.,  2., 15.,  2., 19., 13.,\n",
       "         9., 12., 19., 17.,  9.,  5., 15.,  0.,  6., 13.,  5.,  1.,  9.,\n",
       "        12., 12.,  4., 12.,  0.,  2., 17.,  4., 10., 17., 12., 13., 19.,\n",
       "         5., 19.,  9., 16.,  9., 11., 11.,  5., 15., 13.,  0., 17.,  5.,\n",
       "        14., 15., 15.,  4., 19.,  1.,  9.,  3., 19.,  4., 12., 15., 13.,\n",
       "        10.,  9., 14., 16.,  5., 11., 11.,  4., 13.,  4., 15., 19., 16.,\n",
       "         4.,  3.,  2., 17., 12.,  4.,  6., 15., 15., 19.,  0.,  6., 15.,\n",
       "        13., 15.,  9.,  2., 14.,  9., 10., 11., 12.,  9.,  7.,  2., 13.,\n",
       "        19.,  9., 19., 19.,  9., 11., 14., 16., 13.,  5., 16., 16., 15.,\n",
       "         5., 16., 16., 11., 13., 15., 14.,  9.,  9.,  4., 15., 13.,  0.,\n",
       "         5., 12., 13., 15., 10., 15.,  9., 13.,  0., 14., 11., 18.,  9.,\n",
       "        12.,  5., 12.,  1., 19., 14., 13., 13., 14.,  9., 15.,  8., 16.,\n",
       "         0., 11.,  2., 11., 11., 11., 15., 11.,  4., 12., 18., 16.,  0.,\n",
       "         0., 15.,  8., 19.,  6.,  9., 11.,  5., 14.,  2., 15.,  9., 17.,\n",
       "        11., 12.,  5., 12.,  0., 10.,  0., 15.,  6.,  8.,  2.,  2.,  3.,\n",
       "         3.,  8.,  4.,  4., 12., 10.,  6.,  5., 11.,  9.,  7.,  4.,  5.,\n",
       "         8.,  3.,  5., 16., 16.,  0., 15., 11.,  0.,  3.,  9.,  2., 11.,\n",
       "        17., 10.,  7., 16.,  2.,  3.,  3.,  3.,  7., 14., 16., 16., 11.,\n",
       "        12., 17.,  0., 16.,  3., 13., 19.,  5., 16., 17.,  0., 11., 11.,\n",
       "         9., 13., 15., 15., 11., 16.,  0., 12., 16., 16., 14., 16., 17.,\n",
       "        11.,  2., 13.,  5.,  0.,  9., 12.,  5., 10., 17., 18., 13.,  2.,\n",
       "        14.,  2., 17., 19.,  9., 13.,  5., 12.,  7., 18.,  0.,  8.,  7.,\n",
       "        12.,  6., 16.,  2.,  5.,  6.,  4.,  6., 12., 15., 12.,  9., 10.,\n",
       "         5.,  5.,  4.,  5.,  9.,  8.,  6., 12., 12., 12., 13.,  7., 10.,\n",
       "         7.,  8., 11., 16., 12., 17., 12.,  0., 11., 12., 12., 16., 16.,\n",
       "         4., 15., 12.,  0.,  8.,  4.,  0., 15.,  4.,  7., 16., 13., 19.,\n",
       "        15., 16.,  5., 13., 17., 15., 17.,  3.,  7.,  3., 18.,  3.,  9.,\n",
       "        13.,  8.,  3., 11., 15.,  8., 14., 18., 11., 12.,  3.,  7., 13.,\n",
       "        19., 16., 15., 11., 19., 11.,  8., 15., 17., 11., 17.,  2.,  4.,\n",
       "        16., 17.,  2., 16., 11.,  5., 17., 19., 15.,  3., 12., 14., 12.,\n",
       "         7.,  5., 16., 14., 19.,  9., 16., 14., 11.,  9., 20.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " 0.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MBEDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df_raw = df\n",
    "        self.df = self.create_mbe_dataset(df)\n",
    "    \n",
    "    def create_mbe_dataset(self, df):\n",
    "\n",
    "        df = (df\n",
    "              .loc[:, ['encoded', 'r0', 'r1']]\n",
    "              .melt(id_vars=['encoded'], value_vars=['r0', 'r1'], var_name='round', value_name='value')\n",
    "              .assign(label = lambda x: (x['round'] == 'r1').astype(int))\n",
    "        )\n",
    "        df = df.reindex(df.index.repeat(df['value'])).reset_index()\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_weights(self):\n",
    "        \"\"\"\n",
    "        Number of examples in each class\n",
    "        \"\"\"\n",
    "        counts = (self.df\n",
    "                .groupby('label')\n",
    "                .size()\n",
    "               )\n",
    "        return torch.tensor(counts.loc[1] / counts.loc[0], dtype=torch.float64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # TODO: instead of getting it from the data set, get it from the file...\n",
    "        row = self.df.iloc[idx]\n",
    "        return row['encoded'], float(row['label'])\n",
    "\n",
    "class LEDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Log enrichment dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # TODO: instead of getting it from the data set, get it from the file...\n",
    "        row = self.df.iloc[idx]\n",
    "        return row['encoded'], row['le']\n",
    "\n",
    "class MBEDataModule(L.LightningDataModule):\n",
    "\n",
    "    def __init__(self, data_dir, batch_size = 32):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, enc=\"onehot\", stage=None):\n",
    "        self.train = pd.read_pickle(os.path.join(self.data_dir, f'train_{enc}.pkl'))\n",
    "        self.eval = pd.read_pickle(os.path.join(self.data_dir, f'eval_{enc}.pkl'))\n",
    "        self.test = pd.read_pickle(os.path.join(self.data_dir, f'test_{enc}.pkl'))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(MBEDataset(self.train), batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(LEDataset(self.eval), batch_size=self.batch_size)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(LEDataset(self.test), batch_size=self.batch_size)\n",
    "    \n",
    "# test out dataset class\n",
    "ds = MBEDataset(df_eval)\n",
    "ds[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0544, dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10.,  0.,  0.,  2.,  5., 19.,  9., 12.,  2., 18.,  9.,  3.,  2.,\n",
       "        16.,  9., 15.,  3.,  5.,  7., 14., 13., 18., 18.,  8.,  9.,  8.,\n",
       "        12.,  5., 12., 12., 12., 12.,  8., 12.,  0.,  3., 14.,  6.,  8.,\n",
       "         2.,  2., 15., 14.,  5.,  9., 17.,  9., 12.,  5., 19.,  8., 19.,\n",
       "         9.,  5., 12.,  4., 11.,  5.,  9.,  2.,  8.,  5.,  3., 12., 17.,\n",
       "        11.,  3.,  0.,  2.,  0.,  0.,  0.,  9.,  3.,  6.,  2.,  8.,  0.,\n",
       "        19.,  2., 14., 13.,  9.,  2., 15.,  5.,  2., 11., 12., 19.,  9.,\n",
       "         8., 19., 11.,  6.,  0.,  2.,  0.,  3.,  4., 13.,  3., 14.,  9.,\n",
       "         8.,  3.,  2., 16., 15.,  4.,  5.,  5., 11.,  9.,  5., 14.,  0.,\n",
       "        17.,  4., 13.,  0.,  8.,  8., 14., 17.,  9.,  3., 12.,  9.,  5.,\n",
       "         9., 17.,  3.,  3.,  0.,  0.,  8., 16.,  0., 12.,  5.,  8.,  8.,\n",
       "        14., 12., 17.,  2., 13., 15., 12., 13.,  3., 12.,  2., 15., 15.,\n",
       "        15.,  5., 17.,  5.,  8., 15.,  5.,  8., 13., 12.,  0., 14.,  8.,\n",
       "        14.,  9., 11.,  4.,  5., 13., 16.,  5.,  2., 15.,  3., 15., 17.,\n",
       "        12.,  2., 12., 13., 12.,  9.,  5.,  3., 12., 12.,  0.,  0., 12.,\n",
       "        16., 15.,  9.,  5., 15., 11., 16., 10.,  0., 15.,  5.,  5.,  5.,\n",
       "         0., 12., 10.,  0.,  2., 11., 11.,  3.,  5.,  0.,  2.,  5., 17.,\n",
       "         5., 15., 15., 15.,  5., 11., 18.,  6.,  1.,  2., 15., 13., 18.,\n",
       "         9.,  5.,  2., 14., 17.,  7., 16., 16., 15., 16., 14., 16., 18.,\n",
       "         0.,  9., 12., 16., 19., 11., 11.,  6.,  9., 19.,  8., 13.,  7.,\n",
       "        15., 11.,  5., 16., 15.,  5.,  5.,  0., 16., 11.,  2., 11., 16.,\n",
       "        19.,  4.,  5., 19., 15., 16., 12., 18.,  5., 19.,  4.,  2.,  4.,\n",
       "        11., 14.,  4.,  6.,  1.,  6.,  4., 15., 12., 14.,  2., 18., 13.,\n",
       "        14.,  9.,  7., 11., 11., 11., 18.,  5.,  4., 14., 12.,  8., 14.,\n",
       "         9., 11.,  4.,  8.,  9.,  4., 11.,  7., 13., 17.,  8.,  3., 17.,\n",
       "        16.,  2., 11., 11.,  5., 17.,  8., 16.,  7.,  0., 11., 11.,  9.,\n",
       "        16., 15., 16., 17., 13., 17.,  4., 16.,  2., 15.,  2., 19., 13.,\n",
       "         9., 12., 19., 17.,  9.,  5., 15.,  0.,  6., 13.,  5.,  1.,  9.,\n",
       "        12., 12.,  4., 12.,  0.,  2., 17.,  4., 10., 17., 12., 13., 19.,\n",
       "         5., 19.,  9., 16.,  9., 11., 11.,  5., 15., 13.,  0., 17.,  5.,\n",
       "        14., 15., 15.,  4., 19.,  1.,  9.,  3., 19.,  4., 12., 15., 13.,\n",
       "        10.,  9., 14., 16.,  5., 11., 11.,  4., 13.,  4., 15., 19., 16.,\n",
       "         4.,  3.,  2., 17., 12.,  4.,  6., 15., 15., 19.,  0.,  6., 15.,\n",
       "        13., 15.,  9.,  2., 14.,  9., 10., 11., 12.,  9.,  7.,  2., 13.,\n",
       "        19.,  9., 19., 19.,  9., 11., 14., 16., 13.,  5., 16., 16., 15.,\n",
       "         5., 16., 16., 11., 13., 15., 14.,  9.,  9.,  4., 15., 13.,  0.,\n",
       "         5., 12., 13., 15., 10., 15.,  9., 13.,  0., 14., 11., 18.,  9.,\n",
       "        12.,  5., 12.,  1., 19., 14., 13., 13., 14.,  9., 15.,  8., 16.,\n",
       "         0., 11.,  2., 11., 11., 11., 15., 11.,  4., 12., 18., 16.,  0.,\n",
       "         0., 15.,  8., 19.,  6.,  9., 11.,  5., 14.,  2., 15.,  9., 17.,\n",
       "        11., 12.,  5., 12.,  0., 10.,  0., 15.,  6.,  8.,  2.,  2.,  3.,\n",
       "         3.,  8.,  4.,  4., 12., 10.,  6.,  5., 11.,  9.,  7.,  4.,  5.,\n",
       "         8.,  3.,  5., 16., 16.,  0., 15., 11.,  0.,  3.,  9.,  2., 11.,\n",
       "        17., 10.,  7., 16.,  2.,  3.,  3.,  3.,  7., 14., 16., 16., 11.,\n",
       "        12., 17.,  0., 16.,  3., 13., 19.,  5., 16., 17.,  0., 11., 11.,\n",
       "         9., 13., 15., 15., 11., 16.,  0., 12., 16., 16., 14., 16., 17.,\n",
       "        11.,  2., 13.,  5.,  0.,  9., 12.,  5., 10., 17., 18., 13.,  2.,\n",
       "        14.,  2., 17., 19.,  9., 13.,  5., 12.,  7., 18.,  0.,  8.,  7.,\n",
       "        12.,  6., 16.,  2.,  5.,  6.,  4.,  6., 12., 15., 12.,  9., 10.,\n",
       "         5.,  5.,  4.,  5.,  9.,  8.,  6., 12., 12., 12., 13.,  7., 10.,\n",
       "         7.,  8., 11., 16., 12., 17., 12.,  0., 11., 12., 12., 16., 16.,\n",
       "         4., 15., 12.,  0.,  8.,  4.,  0., 15.,  4.,  7., 16., 13., 19.,\n",
       "        15., 16.,  5., 13., 17., 15., 17.,  3.,  7.,  3., 18.,  3.,  9.,\n",
       "        13.,  8.,  3., 11., 15.,  8., 14., 18., 11., 12.,  3.,  7., 13.,\n",
       "        19., 16., 15., 11., 19., 11.,  8., 15., 17., 11., 17.,  2.,  4.,\n",
       "        16., 17.,  2., 16., 11.,  5., 17., 19., 15.,  3., 12., 14., 12.,\n",
       "         7.,  5., 16., 14., 19.,  9., 16., 14., 11.,  9., 20.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " -0.7777074994126139)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LEDataset(df_eval)\n",
    "le[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64),\n",
       " tensor([1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
       "         1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "         1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "         0., 1., 1., 1., 0., 1., 1., 1., 0., 1.], dtype=torch.float64)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test out datamodule class - takes a while to load pickled data\n",
    "dm = MBEDataModule(procdir, batch_size=BATCH_SIZE)\n",
    "dm.setup()\n",
    "test = next(iter(dm.train_dataloader()))\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "In this case, we'll use a simple feedforward network with two layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0265],\n",
       "        [ 0.0588],\n",
       "        [ 0.0310],\n",
       "        [ 0.0127],\n",
       "        [-0.0194]], dtype=torch.float64, grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MBELogisticRegression(nn.Module):\n",
    "    \"\"\"\n",
    "    Class for logistic regression. \n",
    "    Returns logits by default, or probabilities if probs=True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, 1, dtype = torch.float64)\n",
    "        self.pos_weight = 1 if pos_weight is None else pos_weight\n",
    "\n",
    "    def forward(self, x, probs=False):\n",
    "        \"\"\"\n",
    "        Return logits or probabilities\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        logits = self.linear(x)\n",
    "        if probs:\n",
    "            return torch.sigmoid(logits)\n",
    "        else:\n",
    "            return logits\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Return density ratio, an estimate of log enrichment\n",
    "        \"\"\"\n",
    "        \n",
    "        # get probability for positive class\n",
    "        p = self.forward(x, probs=True)\n",
    "\n",
    "        # density ratio is p/(1-p), adjusted for class imbalance\n",
    "        return p/(1-p) / self.pos_weight\n",
    "\n",
    "class MBEFeedForward(MBELogisticRegression):\n",
    "\n",
    "    def __init__(self, input_size, pos_weight=None, n_units=128):\n",
    "        super().__init__(input_size, pos_weight)\n",
    "        self.n_units = n_units\n",
    "        self.pos_weight = pos_weight\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(input_size, n_units, dtype = torch.float64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_units, 1, dtype = torch.float64),\n",
    "        )\n",
    "\n",
    "\n",
    "model = MBEFeedForward(len(ds[0][0]), pos_weight=ds.get_weights())\n",
    "model(test[0])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9739],\n",
       "        [1.0059],\n",
       "        [0.9783],\n",
       "        [0.9605],\n",
       "        [0.9302]], dtype=torch.float64, grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test[0])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a weighted BCE loss function with the Adam optimizer.  The classes are weighted using the ratio of total reads in r1 vs r0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMBE(L.LightningModule):\n",
    "\n",
    "    def __init__(self, model, lr=0.001, pos_weight = 1):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        self.spearman = stats.spearmanr \n",
    "        self.lr = lr\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.model(x).squeeze()\n",
    "        loss = self.loss(logits, y)\n",
    "        self.log('train_loss', loss, on_step = True, on_epoch = True, prog_bar = True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        with torch.no_grad():\n",
    "            le = self.model.predict(x).squeeze().cpu().numpy()\n",
    "            spearman = self.spearman(le, y.cpu().numpy()).statistic\n",
    "            self.log('val_spearman', spearman, on_step = False, on_epoch = True, prog_bar = True)\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/tlorant@cmri.com.au/aavolve_data/.micromamba/envs/default/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240618_233743-hvzhjdbi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lorant/MBE/runs/hvzhjdbi' target=\"_blank\">feedforward</a></strong> to <a href='https://wandb.ai/lorant/MBE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lorant/MBE' target=\"_blank\">https://wandb.ai/lorant/MBE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lorant/MBE/runs/hvzhjdbi' target=\"_blank\">https://wandb.ai/lorant/MBE/runs/hvzhjdbi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A10') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/data/home/tlorant@cmri.com.au/aavolve_data/.micromamba/envs/default/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c17634c5d75443fada2af01ee520c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val_spearman         -0.008669466711580753\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | MBEFeedForward    | 2.0 M \n",
      "1 | loss  | BCEWithLogitsLoss | 0     \n",
      "--------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "8.065     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d906a3496ba40609a7c5a14c7c4e939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/tlorant@cmri.com.au/aavolve_data/.micromamba/envs/default/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/data/home/tlorant@cmri.com.au/aavolve_data/.micromamba/envs/default/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21fdc2e81c544b98998b5941d56864b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6c01455e7c42a5bae3ffe1a6ccf6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eadd2ebfaa4345f7bf46fc5c9c662073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cf280fcde546ecb596bb6cf66c68d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed6f0b574354754b72207f9af2adc60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b1767515ae471ab6382259fac7f59e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d4f1b610254859a4f5d93628fd0d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04b02ac7cfe4d5b89a7de47817c76f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fad1b8593494a519efc0d45fd198827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d85f46f08564dc5905cde2d765afdc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d856adf6315940058d455ebdfca150a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0439dd7a3c594eb0bec2767fbce8a02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▁▃▃▃▂▁▂▃▂</td></tr><tr><td>train_loss_step</td><td>▇▅▃▃▃▄▄█▄▅▄▅▃▄▅▃▅▅▃▄▆▄▄▆▃▄▄▆▇▅▃▄▄▄▄▂▅▄▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_spearman</td><td>▁█▇█▆▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_loss_epoch</td><td>0.70579</td></tr><tr><td>train_loss_step</td><td>0.72748</td></tr><tr><td>trainer/global_step</td><td>626039</td></tr><tr><td>val_spearman</td><td>0.36864</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">feedforward</strong> at: <a href='https://wandb.ai/lorant/MBE/runs/hvzhjdbi' target=\"_blank\">https://wandb.ai/lorant/MBE/runs/hvzhjdbi</a><br/> View project at: <a href='https://wandb.ai/lorant/MBE' target=\"_blank\">https://wandb.ai/lorant/MBE</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240618_233743-hvzhjdbi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# instantiate lightning model\n",
    "lit_model = LitMBE(model, pos_weight=ds.get_weights())\n",
    "\n",
    "# use weights and biases logger\n",
    "wandb_logger = WandbLogger(project='mbe', name = \"feedforward\")\n",
    "wandb_logger.experiment.config.update({\n",
    "    \"lr\": 0.001,\n",
    "    \"pos_weight\": ds.get_weights(),\n",
    "    \"n_units\": 128,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"max_seq_length\": max_seq_length,\n",
    "    \"arch\": \"feedforward\",\n",
    "    \"enc\": \"onehot\",\n",
    "    \"loss\": \"BCEWithLogitsLoss\",\n",
    "    \"opt\": \"Adam\"\n",
    "})\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(max_epochs=10, logger = wandb_logger)\n",
    "trainer.validate(model = lit_model, datamodule = dm)\n",
    "trainer.fit(model = lit_model, datamodule = dm)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future improvements / things to try:\n",
    "\n",
    " - Weight decay / regularization\n",
    " - Different architechtures\n",
    " - Different encoding (label encoding / embeddings from ESM-2)\n",
    " - Weight decay / regularization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
